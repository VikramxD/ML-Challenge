{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = pd.read_pickle('/home/amazon_ml_challenge/dataset/train_pickle.pkl')\n",
    "processed_train = processed_train.sample(n=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012021     O n e   o f   s i x    6    R a p i d   D e p...\n",
      "1004588      T O Y   D O C T O R   K I T   F O R   K I D ...\n",
      "1982634     M a n u f a c t u r e r   M o d e l    1 5 4 ...\n",
      "314868      C o m p a t i b l e   W i t h    D e s i g n ...\n",
      "1648868      b r  M a t e r i a l    R u b b e r    C l o...\n",
      "                                 ...                        \n",
      "683141      A s s o r t e d   c o l o r s   d o t   s t i...\n",
      "1384310     S h e l l    9 0    c o t t o n  1 0    p o l...\n",
      "2216952        C o z y   M a t e r i a l   M a d e   o f ...\n",
      "1807140     S I Z E    1 1 o z    1 5 o z    P e r f e c ...\n",
      "2135207     W H Y   B U Y   I T    T h i s   P r i n t e ...\n",
      "Name: BULLET_POINTS, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i, row in processed_train.iterrows():\n",
    "    bullet_points = row['BULLET_POINTS']\n",
    "    bullet_points_words = \" \".join(bullet_points).replace(\",\", \"\")\n",
    "    processed_train.at[i, 'BULLET_POINTS'] = bullet_points_words\n",
    "\n",
    "print(processed_train['BULLET_POINTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PRODUCT_ID                                              TITLE  \\\n",
      "1012021     1024120  Rapid Deployment Force 'PARA NINJA' 12' Poseab...   \n",
      "1004588     2693415  39 Pieces Doctor Kit for Kids, Educational Pla...   \n",
      "1982634     1090054                   Frigidaire 154767801 Float Valve   \n",
      "314868      1694624  Galaxy S8 Active Case, AMOOK Shockproof Hybrid...   \n",
      "1648868     1779642       Anupreksha Men's Black Fashion Sandal - 6 UK   \n",
      "\n",
      "                                             BULLET_POINTS  \\\n",
      "1012021   O n e   o f   s i x    6    R a p i d   D e p...   \n",
      "1004588    T O Y   D O C T O R   K I T   F O R   K I D ...   \n",
      "1982634   M a n u f a c t u r e r   M o d e l    1 5 4 ...   \n",
      "314868    C o m p a t i b l e   W i t h    D e s i g n ...   \n",
      "1648868    b r  M a t e r i a l    R u b b e r    C l o...   \n",
      "\n",
      "                                               DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
      "1012021                        twelve inch poseable figure             1225   \n",
      "1004588  toy doctor kit for kid to role play help child...             1121   \n",
      "1982634  this is a genuine replacement part the model n...            10653   \n",
      "314868   features  this hybrid dual layer armor defende...             2201   \n",
      "1648868  elevate your style with this comfortable pair ...             3243   \n",
      "\n",
      "         PRODUCT_LENGTH  \n",
      "1012021     1350.393699  \n",
      "1004588      940.000000  \n",
      "1982634      475.000000  \n",
      "314868       610.000000  \n",
      "1648868      984.251967  \n"
     ]
    }
   ],
   "source": [
    "print(processed_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train['COMPLETE_DESCRIPTION'] = processed_train['TITLE'] + ' ' + processed_train['DESCRIPTION'] + ' ' + processed_train['BULLET_POINTS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Your max_length is set to 200, but you input_length is only 92. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 200, but you input_length is only 117. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=58)\n",
      "Your max_length is set to 200, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n",
      "Your max_length is set to 200, but you input_length is only 48. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rapid Deployment Force 'Para NINJA' 12' Poseable Figure (1992) Poseable figure (1992), twelve inch poseable figure . O n e   o f   s i x   6    R a p i d   D e p l o y m e n t   f i g u r e s   p r o d u c e d  i n   1 9 9 9 .   2  C h a n g e a b l e   o u t f i t s  E x c i t i n g   w e a p o n s    a n d   e q u i p m e n t  S u i t a b  e  f o r   f i g u r e s  O t h e r e r  is  a r e  a l l   1 2   F i g  e r is  f r e e is f r is a r . A r e is  e i r is an e l l e is a l e .  b o r n e    R a n g e r   A n a n e r e r a r a n r r e e r . R a r r r n r e  a n a r e a n n e . A n g r r a   n e a r l a n l a r s e r is a form of an art form of art that is meant to be preserved .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 41. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n",
      "Your max_length is set to 200, but you input_length is only 61. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n",
      "Your max_length is set to 200, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n",
      "Your max_length is set to 200, but you input_length is only 119. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n",
      "Your max_length is set to 200, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 200, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 200, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n",
      "Your max_length is set to 200, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 200, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n",
      "Your max_length is set to 200, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n",
      "Your max_length is set to 200, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 200, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 200, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 200, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 200, but you input_length is only 124. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "model = transformers.pipeline('summarization')\n",
    "\n",
    "# Define the maximum length of the generated summary\n",
    "MAX_LENGTH = 200\n",
    "\n",
    "for i, row in processed_train.iterrows():\n",
    "    # Get the complete description\n",
    "    complete_description = row['COMPLETE_DESCRIPTION']\n",
    "    \n",
    "    # Split the input sequence into chunks of maximum length\n",
    "    chunks = [complete_description[i:i+MAX_LENGTH] for i in range(0, len(complete_description), MAX_LENGTH)]\n",
    "    \n",
    "    # Generate the summary for each chunk using the GPT-2 model\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = model(chunk, max_length=MAX_LENGTH, do_sample=True)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    \n",
    "    # Join the summaries of all chunks into a single summary\n",
    "    summary = ' '.join(summaries)\n",
    "    \n",
    "    # Print the summary\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
