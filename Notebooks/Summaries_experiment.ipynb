{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = pd.read_pickle('/home/amazon_ml_challenge/dataset/train_pickle.pkl')\n",
    "processed_train = processed_train.sample(n=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012021     O n e   o f   s i x    6    R a p i d   D e p...\n",
      "1004588      T O Y   D O C T O R   K I T   F O R   K I D ...\n",
      "1982634     M a n u f a c t u r e r   M o d e l    1 5 4 ...\n",
      "314868      C o m p a t i b l e   W i t h    D e s i g n ...\n",
      "1648868      b r  M a t e r i a l    R u b b e r    C l o...\n",
      "                                 ...                        \n",
      "683141      A s s o r t e d   c o l o r s   d o t   s t i...\n",
      "1384310     S h e l l    9 0    c o t t o n  1 0    p o l...\n",
      "2216952        C o z y   M a t e r i a l   M a d e   o f ...\n",
      "1807140     S I Z E    1 1 o z    1 5 o z    P e r f e c ...\n",
      "2135207     W H Y   B U Y   I T    T h i s   P r i n t e ...\n",
      "Name: BULLET_POINTS, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i, row in processed_train.iterrows():\n",
    "    bullet_points = row['BULLET_POINTS']\n",
    "    bullet_points_words = \" \".join(bullet_points).replace(\",\", \"\")\n",
    "    processed_train.at[i, 'BULLET_POINTS'] = bullet_points_words\n",
    "\n",
    "print(processed_train['BULLET_POINTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-14b526c641c5>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed_train['BULLET_POINTS']  = processed_train['BULLET_POINTS'].str.replace(r'(?<=[a-z])(?=[A-Z0-9])', ' ')\n"
     ]
    }
   ],
   "source": [
    "processed_train['BULLET_POINTS'] = processed_train['BULLET_POINTS'].apply(lambda x: x.replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "processed_train['BULLET_POINTS']  = processed_train['BULLET_POINTS'].str.replace(r'(?<=[a-z])(?=[A-Z0-9])', ' ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PRODUCT_ID                                              TITLE  \\\n",
      "1012021     1024120  Rapid Deployment Force 'PARA NINJA' 12' Poseab...   \n",
      "1004588     2693415  39 Pieces Doctor Kit for Kids, Educational Pla...   \n",
      "1982634     1090054                   Frigidaire 154767801 Float Valve   \n",
      "314868      1694624  Galaxy S8 Active Case, AMOOK Shockproof Hybrid...   \n",
      "1648868     1779642       Anupreksha Men's Black Fashion Sandal - 6 UK   \n",
      "\n",
      "                                             BULLET_POINTS  \\\n",
      "1012021  Oneofsix 6Rapid Deploymentfiguresproducedin 19...   \n",
      "1004588  TOYDOCTORKITFORKIDTOROLEPLAYIncludingeveryimag...   \n",
      "1982634  Manufacturer Model 154767801Genuine Replacemen...   \n",
      "314868   Compatible With Designfor Samsung Galaxy S8Act...   \n",
      "1648868  br Material Rubber Closure Slip Onbrbr Water R...   \n",
      "\n",
      "                                               DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
      "1012021                        twelve inch poseable figure             1225   \n",
      "1004588  toy doctor kit for kid to role play help child...             1121   \n",
      "1982634  this is a genuine replacement part the model n...            10653   \n",
      "314868   features  this hybrid dual layer armor defende...             2201   \n",
      "1648868  elevate your style with this comfortable pair ...             3243   \n",
      "\n",
      "         PRODUCT_LENGTH  \n",
      "1012021     1350.393699  \n",
      "1004588      940.000000  \n",
      "1982634      475.000000  \n",
      "314868       610.000000  \n",
      "1648868      984.251967  \n"
     ]
    }
   ],
   "source": [
    "print(processed_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train['COMPLETE_DESCRIPTION'] = processed_train['TITLE'] + ' ' + processed_train['DESCRIPTION'] + ' ' + processed_train['BULLET_POINTS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 30, but you input_length is only 25. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 30, but you input_length is only 22. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 30, but you input_length is only 23. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 30, but you input_length is only 27. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 30, but you input_length is only 28. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "Your max_length is set to 30, but you input_length is only 8. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=4)\n",
      "Your max_length is set to 30, but you input_length is only 27. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Load the GPT-2 model\n",
    "model = pipeline('summarization',model = 'sshleifer/distilbart-cnn-12-6',device= device)\n",
    "\n",
    "\n",
    "def get_max_length(input_length, fraction):\n",
    "    max_length = int(input_length * fraction)\n",
    "    return max_length\n",
    "\n",
    "\n",
    "# Loop over the rows in the processed_train dataframe\n",
    "for i, row in processed_train.iterrows():\n",
    "    # Get the complete description\n",
    "    complete_description = row['COMPLETE_DESCRIPTION']\n",
    "    \n",
    "    # Define the maximum length of the generated summary based on the length of the input text\n",
    "    max_ratio = 0.3  # Set the maximum ratio between summary length and input text length\n",
    "    max_length = max_length = get_max_length(input_length=int(len(complete_description)), fraction=0.4)\n",
    "    min_length = int(len(complete_description) * 0.1)\n",
    "    \n",
    "    # Generate the summary using the distilbartmodel\n",
    "    summary = model(complete_description, max_length=30, min_length=10, do_sample=True)\n",
    "\n",
    "    processed_train.at[i, 'SUMMARY'] = summary[0]['summary_text']\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train.to_pickle('processed_train.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
